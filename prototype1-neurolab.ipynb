{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a1813e",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/niteshgupta2711/hyper_personized_reinforced_recommendation_system/blob/master/prototype1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e9962d",
   "metadata": {
    "id": "91e9962d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 07:21:48.239684: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 07:21:48.399215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-14 07:21:48.399244: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-14 07:21:48.447750: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-14 07:21:49.582339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-14 07:21:49.582452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-14 07:21:49.582465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# important imports including lineapy for AIRFLOW ORCHESTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b367f85-e686-48d3-8bdc-11892fd84607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # !pip install -r requirements.txt\n",
    "# !pip install -U -q PyDrive\n",
    "# for larger files \n",
    "# wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=FILEID\" -O FILENAME && rm -rf /tmp/cookies.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22de2bac-decb-42b4-85f6-99e1deee88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trick is to figure out the long-name of the file on Google drive from the shared link. The link I needed was:\n",
    "\n",
    "# https://drive.google.com/file/d/1AnsoyBESGSYzRvbMQh5-FWJdgtTo_gOj/view?usp=sharing\n",
    "\n",
    "# from which one can extract the file name as 1AnsoyBESGSYzRvbMQh5-FWJdgtTo_gOj and construct the wget command based on the blog information  and remembering that on a colab Jupyter notebook access to the (linux) system requires a ! placed before wget:\n",
    "\n",
    "# !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1AnsoyBESGSYzRvbMQh5-FWJdgtTo_gOj' -O 'Kijij Listings - edited.xlsx'\n",
    "\n",
    "# Thus the file 'Kijij Listings - edited.xlsx' was downloaded on the local, temporary disk, on the colab cloud-based system. The file name contains blanks and therefore had to be placed within quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ef1db-706e-4772-ba99-218f92300567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750a7264",
   "metadata": {
    "id": "750a7264"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=pd.read_csv('data/AMAZON_FASHION.csv',names=['index','pID','image','ratings','reviewtext','time','cust_id','cust_name','style','summary','unixtime','verified','vote'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec40742d",
   "metadata": {
    "id": "ec40742d",
    "outputId": "3e2dbf4f-9221-43c1-eb30-99927812fcaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pID</th>\n",
       "      <th>image</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>time</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>cust_name</th>\n",
       "      <th>style</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>asin</td>\n",
       "      <td>image</td>\n",
       "      <td>overall</td>\n",
       "      <td>reviewText</td>\n",
       "      <td>reviewTime</td>\n",
       "      <td>reviewerID</td>\n",
       "      <td>reviewerName</td>\n",
       "      <td>style</td>\n",
       "      <td>summary</td>\n",
       "      <td>unixReviewTime</td>\n",
       "      <td>verified</td>\n",
       "      <td>vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1413763200</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>09 28, 2014</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>Sonja Lau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>1411862400</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Love these... I am going to order another pack...</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "      <td>1408924800</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>08 24, 2014</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>Jodi Stoner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1408838400</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         pID  image  ratings  \\\n",
       "0    NaN        asin  image  overall   \n",
       "1    0.0  7106116521    NaN        5   \n",
       "2    1.0  7106116521    NaN        2   \n",
       "3    2.0  7106116521    NaN        4   \n",
       "4    3.0  7106116521    NaN        2   \n",
       "\n",
       "                                          reviewtext         time  \\\n",
       "0                                         reviewText   reviewTime   \n",
       "1                             Exactly what I needed.  10 20, 2014   \n",
       "2  I agree with the other review, the opening is ...  09 28, 2014   \n",
       "3  Love these... I am going to order another pack...  08 25, 2014   \n",
       "4                                too tiny an opening  08 24, 2014   \n",
       "\n",
       "          cust_id     cust_name  style  \\\n",
       "0      reviewerID  reviewerName  style   \n",
       "1  A1D4G1SNUZWQOT         Tracy    NaN   \n",
       "2  A3DDWDH9PX2YX2     Sonja Lau    NaN   \n",
       "3  A2MWC41EW7XL15      Kathleen    NaN   \n",
       "4  A2UH2QQ275NV45   Jodi Stoner    NaN   \n",
       "\n",
       "                                             summary        unixtime  \\\n",
       "0                                            summary  unixReviewTime   \n",
       "1                             perfect replacements!!      1413763200   \n",
       "2  I agree with the other review, the opening is ...      1411862400   \n",
       "3                                My New 'Friends' !!      1408924800   \n",
       "4                                          Two Stars      1408838400   \n",
       "\n",
       "   verified  vote  \n",
       "0  verified  vote  \n",
       "1      True   NaN  \n",
       "2      True   3.0  \n",
       "3     False   NaN  \n",
       "4      True   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "#prod_emb_model_final\n",
    "#final_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967c97f8",
   "metadata": {
    "id": "967c97f8",
    "outputId": "f4a53139-b1a0-4f64-a15d-7479be91a11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['overall', '5', '2', '4', '3', '1'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building the environment with data \n",
    "# this will give positive reinforcements for the agent to learn\n",
    "# using Actor crtic approach\n",
    "# temporal difference\n",
    "# q learning\n",
    "# sarsa\n",
    "# deep sarsa\n",
    "# actor2Crtic\n",
    "\n",
    "dataset.ratings.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce94fb5",
   "metadata": {
    "id": "fce94fb5",
    "outputId": "2a34e734-fca5-43fa-ea64-0ad493ed1ea3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749234"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.cust_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aeace66",
   "metadata": {
    "id": "0aeace66",
    "outputId": "f14f7dea-3330-439b-c858-86b307d3f313"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883637"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2591ba29",
   "metadata": {
    "id": "2591ba29",
    "outputId": "6cceefba-5e31-451d-84cb-517e6da45136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186190"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.pID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a221db",
   "metadata": {
    "id": "d6a221db"
   },
   "outputs": [],
   "source": [
    "# lets understand the data first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f6d6e4",
   "metadata": {
    "id": "38f6d6e4"
   },
   "outputs": [],
   "source": [
    "dataset=dataset.drop(['index','image','time','cust_name','style','reviewtext','unixtime'],axis=1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07962bd3",
   "metadata": {
    "id": "07962bd3",
    "outputId": "01894c63-607d-4e84-e45b-88367187f851"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>ratings</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pID, ratings, cust_id, summary, verified, vote]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.ratings=='overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb18e51e",
   "metadata": {
    "id": "cb18e51e",
    "outputId": "b968fb80-467e-42bc-c49b-6afab00ed58e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803736"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.vote.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99583045",
   "metadata": {
    "id": "99583045",
    "outputId": "4299a1af-c746-432c-ecd8-9cc73d5b481c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9095771227325248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "803736/883637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a04476",
   "metadata": {
    "id": "93a04476",
    "outputId": "83a00c53-f155-4a1d-fe1c-bedbb5cde2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 883636 entries, 1 to 883636\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   pID       883636 non-null  object\n",
      " 1   ratings   883636 non-null  object\n",
      " 2   cust_id   883636 non-null  object\n",
      " 3   summary   883099 non-null  object\n",
      " 4   verified  883636 non-null  object\n",
      " 5   vote      79900 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 10 % data in vote is not present\n",
    "dataset.info()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cbad4f7",
   "metadata": {
    "id": "0cbad4f7"
   },
   "outputs": [],
   "source": [
    "# we are going to embed the pID(product ids) baed on ratings \n",
    "# getting the dataset for embedding the profuct id\n",
    "# we will be embedding the product id s in latent space 128 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af72963f",
   "metadata": {
    "id": "af72963f"
   },
   "outputs": [],
   "source": [
    "embedding_dataset=dataset.drop(['cust_id','verified','vote'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "068129d0",
   "metadata": {
    "id": "068129d0"
   },
   "outputs": [],
   "source": [
    "# embedding_dataset.head()\n",
    "# l=[]\n",
    "# embedding_dataset['summary'].apply(lambda review:[l.append(x) for x in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18e07764",
   "metadata": {
    "id": "18e07764"
   },
   "outputs": [],
   "source": [
    "Xtrain,ytrain=embedding_dataset.drop(['ratings'],axis=1),embedding_dataset['ratings'].apply(lambda x:str(int(x)-1)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2123bd44",
   "metadata": {
    "id": "2123bd44"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bcdb86c",
   "metadata": {
    "id": "3bcdb86c"
   },
   "outputs": [],
   "source": [
    "Xtrain.summary=Xtrain.summary.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e90dfb2",
   "metadata": {
    "id": "9e90dfb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 07:39:52.377207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-14 07:39:52.377262: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-14 07:39:52.377296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1b009e0739df): /proc/driver/nvidia/version does not exist\n",
      "2022-11-14 07:39:52.377638: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "product_embeds=TextVectorization(max_tokens=186191,output_sequence_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e99c54a3",
   "metadata": {
    "id": "e99c54a3"
   },
   "outputs": [],
   "source": [
    "# summary_embeds=TextVectorization(max_tokens=6000,output_sequence_length=30)\n",
    "product_embeds.adapt(Xtrain.pID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d98d375",
   "metadata": {
    "id": "8d98d375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:           247Gi        16Gi       206Gi       3.0Mi        24Gi       229Gi\n",
      "Swap:             0B          0B          0B\n",
      "Total:         247Gi        16Gi       206Gi\n"
     ]
    }
   ],
   "source": [
    "# summary_embeds.adapt(Xtrain.summary)\n",
    "!free -th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a20d0fd",
   "metadata": {
    "id": "5a20d0fd",
    "outputId": "e33f9d50-5479-4bc8-b6ea-8f2fd2e09c44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [9]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_embeds(Xtrain.tail()['pID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b962e",
   "metadata": {
    "id": "7c7b962e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31932d3a",
   "metadata": {
    "id": "31932d3a",
    "outputId": "df1a43d9-457b-4240-8aa3-fe72778bbec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7106116521', 'B00007GDFV', 'B00008JOQI', ..., 'B01HJHTH5U',\n",
       "       'B01HJHF97K', 'B01HJG5NMW'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.pID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59e3e0",
   "metadata": {
    "id": "4d59e3e0"
   },
   "outputs": [],
   "source": [
    "# product embeds completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa92faf8",
   "metadata": {
    "id": "aa92faf8"
   },
   "outputs": [],
   "source": [
    "product_input=tf.keras.Input(shape=(),dtype=tf.string)\n",
    "te=product_embeds(product_input)\n",
    "embedding=tf.keras.layers.Embedding(input_dim=186191,output_dim=128, input_length=1,)(te)\n",
    "sq=tf.keras.backend.squeeze(embedding,1)\n",
    "model1=tf.keras.Model(product_input,sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08b15a61",
   "metadata": {
    "id": "08b15a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub) (1.23.4)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# model1(np.array(Xtrain.pID.values[10:12]))\n",
    "!pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ab69aed",
   "metadata": {
    "id": "7ab69aed",
    "outputId": "bcc7312d-93fa-4c67-c9f2-3f8c91083f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",trainable=False,input_shape=[])\n",
    "embeddings = embed([\"product was n\"])\n",
    "\n",
    "# this willl take more time to load as it is 1 gb module loaded\n",
    "#print(embeddings)\n",
    "# embL=hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",trainable=False,input_shape=[])\n",
    "\n",
    "# The following are example embedding output of 512 dimensions per sentence\n",
    "# Embedding for: The quick brown fox jumps over the lazy dog.\n",
    "# [-0.03133016 -0.06338634 -0.01607501, ...]\n",
    "# Embedding for: I am a sentence for which I would like to get its embedding.\n",
    "# [0.05080863 -0.0165243   0.01573782, ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3284b6ff",
   "metadata": {
    "id": "3284b6ff"
   },
   "outputs": [],
   "source": [
    "summary_input=tf.keras.Input(shape=(),dtype=tf.string)\n",
    "use=embed(summary_input)\n",
    "final=tf.keras.layers.Dense(128,activation='relu')(use)\n",
    "model2=tf.keras.Model(summary_input,final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b467a57e",
   "metadata": {
    "id": "b467a57e"
   },
   "outputs": [],
   "source": [
    "# model2(Xtrain.summary.values[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18924984",
   "metadata": {
    "id": "18924984"
   },
   "outputs": [],
   "source": [
    "# model1.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb93b44",
   "metadata": {
    "id": "3bb93b44"
   },
   "outputs": [],
   "source": [
    "x=tf.keras.layers.Concatenate()([model1.output,model2.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7682a866",
   "metadata": {
    "id": "7682a866"
   },
   "outputs": [],
   "source": [
    "dense_1= tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "dense_2=tf.keras.layers.Dense(256,activation='relu')(dense_1)\n",
    "drop_1=tf.keras.layers.Dropout(0.4)(dense_2)\n",
    "dense_3=tf.keras.layers.Dense(128,activation='relu')(drop_1)\n",
    "drop_2=tf.keras.layers.Dropout(0.4)(dense_3)\n",
    "dense_4=tf.keras.layers.Dense(64,activation='relu')(drop_2)\n",
    "dense_5=tf.keras.layers.Dense(5, activation='softmax')(dense_4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c00251d",
   "metadata": {
    "id": "7c00251d"
   },
   "outputs": [],
   "source": [
    "final_model=tf.keras.Model(inputs=[product_input,summary_input],outputs=dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b41eedb5",
   "metadata": {
    "id": "b41eedb5"
   },
   "outputs": [],
   "source": [
    "# img_file = './model_arch.png'\n",
    "\n",
    "# tf.keras.utils.plot_model(final_model, to_file=img_file, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63493b4e",
   "metadata": {
    "id": "63493b4e",
    "outputId": "02f85887-5ab3-47b8-e343-72f499f50ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "plot_model(final_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec14ddab",
   "metadata": {
    "id": "ec14ddab",
    "outputId": "3da9c503-580f-458d-a654-03d62a00f59a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install netron\n",
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab0afe7c",
   "metadata": {
    "id": "ab0afe7c",
    "outputId": "0f5e6614-4594-4abe-940e-475a8d222817"
   },
   "outputs": [],
   "source": [
    "# model1=tf.keras.models.load_model('prod_emb_model_final/prod_emb_model_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62ac777e",
   "metadata": {
    "id": "62ac777e",
    "outputId": "93e6cb66-e5cd-4a8a-f9b5-07243a4e80ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 1)           0           ['input_1[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 128)       23832448    ['text_vectorization[0][0]']     \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       (None, 512)          256797824   ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 128)         0           ['embedding[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['keras_layer[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['tf.compat.v1.squeeze[0][0]',   \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          131584      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          131328      ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 280,958,848\n",
      "Trainable params: 24,161,024\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d063e258",
   "metadata": {
    "id": "d063e258"
   },
   "outputs": [],
   "source": [
    "data1=tf.data.Dataset.from_tensor_slices(Xtrain.pID.values)\n",
    "data2=tf.data.Dataset.from_tensor_slices(Xtrain.summary.values)\n",
    "target=tf.data.Dataset.from_tensor_slices(ytrain.values)\n",
    "daata=tf.data.Dataset.zip(((data1,data2),target)).batch(32).prefetch(1)\n",
    "# tf.data.Dataset.zip((features,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2156de4",
   "metadata": {
    "id": "f2156de4"
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb4533",
   "metadata": {
    "id": "badb4533"
   },
   "outputs": [],
   "source": [
    "import netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daa95b8a",
   "metadata": {
    "id": "daa95b8a",
    "outputId": "bf220d8c-996c-4f69-e93d-dc18d7cfbfe2"
   },
   "outputs": [],
   "source": [
    "# final_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a52b42",
   "metadata": {
    "id": "64a52b42"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16261e3d",
   "metadata": {
    "id": "16261e3d"
   },
   "outputs": [],
   "source": [
    "# # final_model.fit(daata,epochs=1)\n",
    "# model2(Xtrain.summary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e22153",
   "metadata": {
    "id": "39e22153"
   },
   "outputs": [],
   "source": [
    "netron.start('model',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c38c317c",
   "metadata": {
    "id": "c38c317c"
   },
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "#!tensorboard --logdir='logs'\n",
    "# launch the above in a shell \n",
    "# and look for metrics you want to see\n",
    "# tensorboard dev upload --logdir notebooks/logs\n",
    "# look at the realtime progress in tensorboard using above command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94df2d7e",
   "metadata": {
    "id": "94df2d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11627/27614 [===========>..................] - ETA: 1:05:15 - loss: 5.4898"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorBoard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_model.fit(daata,epochs=1,callbacks=[tf.keras.callbacks.TensorBoard(log_dir='logs')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "73b25d9d",
   "metadata": {
    "id": "73b25d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7eff0924",
   "metadata": {
    "id": "7eff0924",
    "outputId": "062a8898-9538-42e3-9c78-2228c15f28d7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-daf32486442cb6b6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-daf32486442cb6b6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2935962",
   "metadata": {
    "id": "b2935962"
   },
   "outputs": [],
   "source": [
    "# given a cust_id and producti_id give the environment rewards and s states\n",
    "# when you get a product_id as  a recommendation , you need to get the embedding of that product_id as next state\n",
    "# and again the cust_id and product_id we will get the env rewrds and states,\n",
    "# we will end the recommendation when it recommends \"\"\n",
    "# this is the current plan\n",
    "#  we will use A2C technique in reinforcement learining to reforce recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48b327",
   "metadata": {
    "id": "8c48b327"
   },
   "outputs": [],
   "source": [
    "# we will be using sklearn minibatchKmeans algorihtm for clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8318a",
   "metadata": {
    "id": "2df8318a"
   },
   "outputs": [],
   "source": [
    "# once you get the cust_id get all the products bought by that customer, and the product_id that got recommended\n",
    "# check whether or not recommended product is similar to products bought by the customer\n",
    "# get the recommended product_ids embeds\n",
    "# get the products bought by the customer embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971175f4",
   "metadata": {
    "id": "971175f4",
    "outputId": "36038ee8-d8bd-4847-e632-eb675e46ac46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b01hjgx04a'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_embeds.get_vocabulary()[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d383867",
   "metadata": {
    "id": "9d383867",
    "outputId": "f863feae-ba3d-4b3a-d41c-55159c002018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([182638], dtype=int64)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_embeds('b000yfsr5g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506db35",
   "metadata": {
    "id": "0506db35"
   },
   "outputs": [],
   "source": [
    "# model1(np.array([['b000yfsr5g',]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e487a0",
   "metadata": {
    "id": "32e487a0"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5dd8c",
   "metadata": {
    "id": "55c5dd8c"
   },
   "outputs": [],
   "source": [
    "# class recommendation_Env:\n",
    "    \n",
    "#     def __init__(self,data_path,text_vectorizer,emb_model,recusive_model):\n",
    "#         self.dataset=pd.read_csv(data_path,names=['index','pID','image','ratings','reviewtext','time','cust_id','cust_name','style','summary','unixtime','verified','vote'],low_memory=False)\n",
    "#         self.t=text_vectorizer\n",
    "#         self.vocab=self.t.get_vocabulary()\n",
    "#         self.pr_model=emb_model\n",
    "#         self.gcwd=self._get_cluster_with_data()\n",
    "#         self.r_model=recursive_model\n",
    "    \n",
    "#     def _get_products(self,cust_id:str):\n",
    "#         return self.dataset[self.dataset.cust_id==cust_id]['pID'].values\n",
    "    \n",
    "#     def _get_cluster_with_data(self):\n",
    "#         self.kmeans = MiniBatchKMeans(n_clusters=5,random_state=42,batch_size=1024,max_iter=100)\n",
    "#         self.kmeans.fit(self.pr_model(np.array(self.vocab).reshape(-1,1)).numpy())\n",
    "#         return self.kmeans\n",
    "    \n",
    "#     def _get_pr_from_index(self,index):\n",
    "#         return self.vocab[index]\n",
    "    \n",
    "#     def reset(self):\n",
    "#         return '[UNK]'\n",
    "    \n",
    "#     def _get_cluster_index(self,product_embedding):\n",
    "#         #self.cluster=self._embeds_with_data()\n",
    "        \n",
    "#         return self.gcwd.predict(product_embedding)\n",
    "    \n",
    "#     def _get_emb_product(self,pr_id):\n",
    "#         return self.pr_model(np.array([[self._get_pr_from_index(pr_id)]]))\n",
    "    \n",
    "#     def _get_cluster_from_cust_id(self,index_for_recommended_product,cust_id):\n",
    "#         self.embeds_from_cust_id=self.pr_model(self._get_products(cust_id)).numpy()\n",
    "#         self.cluster_ids_for_customer=self._get_cluster_index(self.embeds_from_cust_id)\n",
    "#         self.embeds_from_recommenation=self.pr_model(np.array([[self._get_pr_from_index(index_for_recommended_product)]])).numpy()\n",
    "#         self.cluster_id_for_recomendation=self._get_cluster_index(self.embeds_from_recommenation)\n",
    "#         return self.cluster_ids_for_customer,self.cluster_id_for_recomendation\n",
    "    \n",
    "#     def step(self,action,agent):\n",
    "#         emb__=self._get_emb_product(action)\n",
    "#         next_state=\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab275aec",
   "metadata": {
    "id": "ab275aec"
   },
   "outputs": [],
   "source": [
    "# env=recommendation_Env('../data/AMAZON_FASHION.csv',product_embeds,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866df75",
   "metadata": {
    "id": "f866df75"
   },
   "outputs": [],
   "source": [
    "# env._get_products('A1D4G1SNUZWQOT')\n",
    "# kp=model1(np.array([['A1D4G1SNUZWQOT']])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44ac4f",
   "metadata": {
    "id": "1f44ac4f"
   },
   "outputs": [],
   "source": [
    "# # model1(np.array(product_embeds.get_vocabulary()).reshape(-1,1)).numpy()\n",
    "# env._get_cluster_index(kp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce04b6",
   "metadata": {
    "id": "84ce04b6"
   },
   "outputs": [],
   "source": [
    "# env._get_cluster_from_cust_id('A3O90PACS7B61K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36379401",
   "metadata": {
    "id": "36379401",
    "outputId": "ca7567c8-9a23-42aa-ec5b-c7a8b536d7da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A1D4G1SNUZWQOT', 'A3DDWDH9PX2YX2', 'A2MWC41EW7XL15', ...,\n",
       "       'A3O90PACS7B61K', 'A2HO94I89U3LNH', 'A2RSX9E79DUHRX'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cust_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827e3a2",
   "metadata": {
    "id": "a827e3a2"
   },
   "outputs": [],
   "source": [
    "# env._get_emb_product(456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649fc41",
   "metadata": {
    "id": "d649fc41",
    "outputId": "5fba50be-a9e6-4798-98a0-8303ca4976f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model2.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1daa122",
   "metadata": {
    "id": "e1daa122",
    "outputId": "91117336-efc6-4593-d718-c89875f17fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'model.h5' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netron.start('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47deff2",
   "metadata": {
    "id": "e47deff2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e87095",
   "metadata": {
    "id": "79e87095"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d0cc0",
   "metadata": {
    "id": "7e3d0cc0"
   },
   "outputs": [],
   "source": [
    "# kmeans = MiniBatchKMeans(n_clusters=5,\n",
    "#                          random_state=42,\n",
    "#                           batch_size=1024,\n",
    "#                         max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18662ce",
   "metadata": {
    "id": "b18662ce"
   },
   "outputs": [],
   "source": [
    "# kmeans.fit(model1(np.array(product_embeds.get_vocabulary()).reshape(-1,1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d797f09",
   "metadata": {
    "id": "5d797f09"
   },
   "outputs": [],
   "source": [
    "# kl=kmeans.predict(model1(np.array(product_embeds.get_vocabulary()).reshape(-1,1)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2453ccf",
   "metadata": {
    "id": "e2453ccf"
   },
   "outputs": [],
   "source": [
    "# set(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e2133",
   "metadata": {
    "id": "535e2133"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72c2de",
   "metadata": {
    "id": "ff72c2de"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=pd.read_csv('../data/AMAZON_FASHION.csv',names=['index','pID','image','ratings','reviewtext','time','cust_id','cust_name','style','summary','unixtime','verified','vote'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0630ea8",
   "metadata": {
    "id": "c0630ea8",
    "outputId": "56ca0017-cf1e-432d-cf02-794efb0a46db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pID</th>\n",
       "      <th>image</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>time</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>cust_name</th>\n",
       "      <th>style</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>asin</td>\n",
       "      <td>image</td>\n",
       "      <td>overall</td>\n",
       "      <td>reviewText</td>\n",
       "      <td>reviewTime</td>\n",
       "      <td>reviewerID</td>\n",
       "      <td>reviewerName</td>\n",
       "      <td>style</td>\n",
       "      <td>summary</td>\n",
       "      <td>unixReviewTime</td>\n",
       "      <td>verified</td>\n",
       "      <td>vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1413763200</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>09 28, 2014</td>\n",
       "      <td>A3DDWDH9PX2YX2</td>\n",
       "      <td>Sonja Lau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I agree with the other review, the opening is ...</td>\n",
       "      <td>1411862400</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Love these... I am going to order another pack...</td>\n",
       "      <td>08 25, 2014</td>\n",
       "      <td>A2MWC41EW7XL15</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My New 'Friends' !!</td>\n",
       "      <td>1408924800</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>too tiny an opening</td>\n",
       "      <td>08 24, 2014</td>\n",
       "      <td>A2UH2QQ275NV45</td>\n",
       "      <td>Jodi Stoner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1408838400</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         pID  image  ratings  \\\n",
       "0    NaN        asin  image  overall   \n",
       "1    0.0  7106116521    NaN        5   \n",
       "2    1.0  7106116521    NaN        2   \n",
       "3    2.0  7106116521    NaN        4   \n",
       "4    3.0  7106116521    NaN        2   \n",
       "\n",
       "                                          reviewtext         time  \\\n",
       "0                                         reviewText   reviewTime   \n",
       "1                             Exactly what I needed.  10 20, 2014   \n",
       "2  I agree with the other review, the opening is ...  09 28, 2014   \n",
       "3  Love these... I am going to order another pack...  08 25, 2014   \n",
       "4                                too tiny an opening  08 24, 2014   \n",
       "\n",
       "          cust_id     cust_name  style  \\\n",
       "0      reviewerID  reviewerName  style   \n",
       "1  A1D4G1SNUZWQOT         Tracy    NaN   \n",
       "2  A3DDWDH9PX2YX2     Sonja Lau    NaN   \n",
       "3  A2MWC41EW7XL15      Kathleen    NaN   \n",
       "4  A2UH2QQ275NV45   Jodi Stoner    NaN   \n",
       "\n",
       "                                             summary        unixtime  \\\n",
       "0                                            summary  unixReviewTime   \n",
       "1                             perfect replacements!!      1413763200   \n",
       "2  I agree with the other review, the opening is ...      1411862400   \n",
       "3                                My New 'Friends' !!      1408924800   \n",
       "4                                          Two Stars      1408838400   \n",
       "\n",
       "   verified  vote  \n",
       "0  verified  vote  \n",
       "1      True   NaN  \n",
       "2      True   3.0  \n",
       "3     False   NaN  \n",
       "4      True   NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c312d",
   "metadata": {
    "id": "c90c312d",
    "outputId": "e0be488a-08b1-4d9a-d09e-36af342d0e6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pID</th>\n",
       "      <th>image</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>time</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>cust_name</th>\n",
       "      <th>style</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixtime</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7106116521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Exactly what I needed.</td>\n",
       "      <td>10 20, 2014</td>\n",
       "      <td>A1D4G1SNUZWQOT</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfect replacements!!</td>\n",
       "      <td>1413763200</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         pID image ratings              reviewtext         time  \\\n",
       "1    0.0  7106116521   NaN       5  Exactly what I needed.  10 20, 2014   \n",
       "\n",
       "          cust_id cust_name style                 summary    unixtime  \\\n",
       "1  A1D4G1SNUZWQOT     Tracy   NaN  perfect replacements!!  1413763200   \n",
       "\n",
       "  verified vote  \n",
       "1     True  NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['cust_id']=='A1D4G1SNUZWQOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9027be",
   "metadata": {
    "id": "7c9027be"
   },
   "outputs": [],
   "source": [
    "#dataset.cust_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fd02c",
   "metadata": {
    "id": "907fd02c",
    "outputId": "2b10b766-cb9b-4c6b-a6d0-d0c736ca8c4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883637"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5a09a",
   "metadata": {
    "id": "8dc5a09a",
    "outputId": "1714d426-a42e-4a46-ef69-ed9c672719fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478979490446868"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "749234/883637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504a502",
   "metadata": {
    "id": "8504a502"
   },
   "outputs": [],
   "source": [
    "cust_embeddings=TextVectorization(max_tokens=749235,output_sequence_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a66b2",
   "metadata": {
    "id": "542a66b2"
   },
   "outputs": [],
   "source": [
    "cust_embeddings.adapt(dataset.cust_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734472d1",
   "metadata": {
    "id": "734472d1",
    "outputId": "6c9bcbbe-72be-4836-ab8e-73e836550a08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=int64, numpy=\n",
       "array([[     2],\n",
       "       [676759],\n",
       "       [279687],\n",
       "       [425609],\n",
       "       [383937],\n",
       "       [152219],\n",
       "       [499099],\n",
       "       [155075],\n",
       "       [686802],\n",
       "       [ 99186]], dtype=int64)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_embeddings(dataset.cust_id.values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f5192",
   "metadata": {
    "id": "fc9f5192"
   },
   "outputs": [],
   "source": [
    "# import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bcaf71",
   "metadata": {
    "id": "92bcaf71"
   },
   "outputs": [],
   "source": [
    "# with open('cust_emb.pkl','wb') as f:\n",
    "#     pickle.dump(cust_embeddings.get_vocabulary(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf8924",
   "metadata": {
    "id": "feaf8924",
    "outputId": "9463db87-c8ec-46fe-9185-c314e0705539"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749235"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cust_embeddings.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b10b4",
   "metadata": {
    "id": "268b10b4"
   },
   "outputs": [],
   "source": [
    "cust_inputd=tf.keras.Input(shape=(),dtype=tf.string)\n",
    "cust_int=cust_embeddings(cust_inputd)\n",
    "emb_c=tf.keras.layers.Embedding(input_dim=749235,output_dim=128)(cust_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d13cb",
   "metadata": {
    "id": "4f2d13cb"
   },
   "outputs": [],
   "source": [
    "#final_inps=tf.keras.Input(shape=(128,))\n",
    "#reshaped=tf.keras.layers.Reshape((1,128))(emb_c)\n",
    "dense_1=tf.keras.layers.Dense(128,activation='relu',name='initial_dense_layer',)(emb_c)\n",
    "norm_1=tf.keras.layers.BatchNormalization()(dense_1)\n",
    "dense_2=tf.keras.layers.Dense(512,activation='relu')(norm_1)\n",
    "actor=tf.keras.layers.Dense(186191,activation=None)(dense_2)\n",
    "critic=tf.keras.layers.Dense(1)(dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdbcb4",
   "metadata": {
    "id": "22fdbcb4"
   },
   "outputs": [],
   "source": [
    "a2c_model=tf.keras.Model(cust_inputd,[critic,actor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36947127",
   "metadata": {
    "id": "36947127",
    "outputId": "600239c6-85d2-4fda-d47f-8b533afb0df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_1 (TextVect  (None, 1)           0           ['input_1[0][0]']                \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 128)       95902080    ['text_vectorization_1[0][0]']   \n",
      "                                                                                                  \n",
      " initial_dense_layer (Dense)    (None, 1, 128)       16512       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 128)      512         ['initial_dense_layer[0][0]']    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 512)       66048       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 1)         513         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 186191)    95515983    ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 191,501,648\n",
      "Trainable params: 191,501,392\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "a2c_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212573b",
   "metadata": {
    "id": "b212573b"
   },
   "outputs": [],
   "source": [
    "# final_model=tf.keras.Model(cust_inputd,[critic,actor])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78902f89",
   "metadata": {
    "id": "78902f89"
   },
   "outputs": [],
   "source": [
    "# netron.start('actor_model.h5')\n",
    "prod_model=tf.keras.Model(dense_1,[critic,actor])\n",
    "# this is recursiv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190aafc",
   "metadata": {
    "id": "b190aafc"
   },
   "outputs": [],
   "source": [
    "# dont use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaca8e0",
   "metadata": {
    "id": "edaca8e0",
    "outputId": "e9719125-0e39-4ed4-e382-d6bc84b72808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[-0.18694483]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 186191), dtype=float32, numpy=\n",
       " array([[[ 2.5274879e-03, -6.9326963e-03,  9.4242732e-04, ...,\n",
       "          -8.1937644e-05,  1.8577999e-03, -3.6084333e-03]]], dtype=float32)>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_model(model1(np.array([[['7106116521']]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856bcf8",
   "metadata": {
    "id": "3856bcf8"
   },
   "outputs": [],
   "source": [
    "cust_emb_model=tf.keras.Model(cust_inputd,emb_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1aff6",
   "metadata": {
    "id": "c4d1aff6",
    "outputId": "51866e85-70bf-484e-e42b-73b65e062d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "a2c_model.save('a2c_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb32e4",
   "metadata": {
    "id": "decb32e4"
   },
   "outputs": [],
   "source": [
    "# netron.start('a2c_model.h5')\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3e035",
   "metadata": {
    "id": "f2b3e035"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, r_model,emb_model,gamma=0.99):\n",
    "        self.gamma = gamma\n",
    "        # here embedding model is product embedding model\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        self.actor_critic = a2c_model\n",
    "        self.r_model=r_model\n",
    "        self.pr_model=emb_model\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        \n",
    "        _, action_probabilities = self.actor_critic(np.array([state]))\n",
    "        action_probabilities = tf.nn.softmax(action_probabilities)\n",
    "        action_probabilities = action_probabilities.numpy()\n",
    "        dist = tfp.distributions.Categorical(probs=action_probabilities, dtype=tf.float32)\n",
    "        action = dist.sample()\n",
    "        return int(action.numpy()[0])\n",
    "    \n",
    "    def get_action_r(self,state):\n",
    "        # the state here should be of shape (1,128)\n",
    "        _, action_probabilities = self.r_model(np.array([state]))\n",
    "        action_probabilities = tf.nn.softmax(action_probabilities)\n",
    "        action_probabilities = action_probabilities.numpy()\n",
    "        dist = tfp.distributions.Categorical(probs=action_probabilities, dtype=tf.float32)\n",
    "        action = dist.sample()\n",
    "        return int(action.numpy()[0])\n",
    "    \n",
    "    def actor_loss(self, prob, action, td):\n",
    "        \n",
    "        \n",
    "        prob = tf.nn.softmax(prob)\n",
    "        dist = tfp.distributions.Categorical(probs=prob,dtype=tf.float32)\n",
    "        log_prob = dist.log_prob(action)\n",
    "        loss = -log_prob * td\n",
    "        return loss\n",
    "        \n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        state = np.array([state])\n",
    "        next_state = np.array([next_state])\n",
    "        with tf.GradientTape() as tape:\n",
    "            value, action_probabilities = self.r_model(self.pr_model(np.array([[state]])), training=True)\n",
    "            value_next_st, _ = self.r_model(self.pr_model(np.array([[next_state]])), training=True)\n",
    "            td = reward + self.gamma * value_next_st * (1 - int(done)) - value\n",
    "            actor_loss = self.actor_loss(action_probabilities, action, td)\n",
    "            critic_loss = td ** 2\n",
    "            total_loss = actor_loss + critic_loss\n",
    "        grads = tape.gradient(total_loss, self.r_model.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grads, self.r_model.trainable_variables))\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe5168",
   "metadata": {
    "id": "62fe5168"
   },
   "outputs": [],
   "source": [
    "def train(agent, env, episodes,emb_model):\n",
    "    # emb_model here is product emb model\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        done = False\n",
    "        state = '[UNK]'\n",
    "        total_reward = 0\n",
    "        all_loss = []\n",
    "        while not done:\n",
    "            action = agent.get_action_r(emb_model(np.array([state])))\n",
    "            # print('___________got the action______________')\n",
    "            next_state, reward, done = env.step(action,agent,state)\n",
    "            print(next_state)\n",
    "            loss = agent.learn(state, action, reward, next_state, done)\n",
    "            all_loss.append(loss)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                print(\"\\n\")\n",
    "                print(f\"Episode#:{episode} ep_reward:{total_reward}\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b22f83",
   "metadata": {
    "id": "01b22f83",
    "outputId": "4a577d0d-bd25-4171-fc43-673d86404ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[0.0004417]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 186191), dtype=float32, numpy=\n",
       " array([[[ 9.4883656e-04,  1.8872769e-04,  6.9058716e-04, ...,\n",
       "           2.1902465e-04,  9.9052489e-04, -4.5849956e-05]]], dtype=float32)>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_model(np.array([['[UNK]']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37596e5f",
   "metadata": {
    "id": "37596e5f"
   },
   "outputs": [],
   "source": [
    "agent=Agent(prod_model,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2367907",
   "metadata": {
    "id": "b2367907",
    "outputId": "fcff95c0-3c96-403b-a62c-a63d1edbd7b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54481"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_action('[UNK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc07bdd",
   "metadata": {
    "id": "adc07bdd"
   },
   "outputs": [],
   "source": [
    "# class recommendation_Env:\n",
    "    \n",
    "#     def __init__(self,data_path,text_vectorizer,emb_model,recursive_model):\n",
    "#         #emb_model is product embeds model\n",
    "#         # text vecorizer is products text_vectorizer\n",
    "#         # emb_model is model for product embedding model\n",
    "#         self.dataset=pd.read_csv(data_path,names=['index','pID','image','ratings','reviewtext','time','cust_id','cust_name','style','summary','unixtime','verified','vote'],low_memory=False)\n",
    "#         self.t=text_vectorizer\n",
    "#         self.vocab=self.t.get_vocabulary()\n",
    "#         self.pr_model=emb_model\n",
    "#         self.gcwd=self._get_cluster_with_data()\n",
    "#         self.r_model=recursive_model\n",
    "    \n",
    "#     def _get_products(self,cust_id:str):\n",
    "#         return self.dataset[self.dataset.cust_id==cust_id]['pID'].values\n",
    "    \n",
    "#     def _get_cluster_with_data(self):\n",
    "#         self.kmeans = MiniBatchKMeans(n_clusters=5,random_state=42,batch_size=1024,max_iter=100)\n",
    "#         self.kmeans.fit(self.pr_model(np.array(self.vocab).reshape(-1,1)).numpy())\n",
    "#         return self.kmeans\n",
    "    \n",
    "#     def _get_pr_from_index(self,index):\n",
    "#         return self.vocab[index]\n",
    "    \n",
    "#     def reset(self):\n",
    "#         return '[UNK]'\n",
    "    \n",
    "#     def _get_cluster_index(self,product_embedding):\n",
    "#         #self.cluster=self._embeds_with_data()\n",
    "        \n",
    "#         return self.gcwd.predict(product_embedding)\n",
    "    \n",
    "#     def _get_emb_product(self,pr_id):\n",
    "#         return self.pr_model(np.array([[self._get_pr_from_index(pr_id)]]))\n",
    "    \n",
    "#     def _get_cluster_from_cust_id(self,index_for_recommended_product,state):\n",
    "#         #self.embeds_from_cust_id=self.pr_model(self._get_products(cust_id)).numpy()\n",
    "#         self.embeds_from_cust_id=self.pr_model(np.array([[state]])).numpy()\n",
    "#         self.cluster_ids_for_customer=self._get_cluster_index(self.embeds_from_cust_id)\n",
    "#         self.embeds_from_recommenation=self.pr_model(np.array([[index_for_recommended_product]])).numpy()\n",
    "#         self.cluster_id_for_recomendation=self._get_cluster_index(self.embeds_from_recommenation)\n",
    "#         return self.cluster_id_for_recomendation.tolist(),self.cluster_ids_for_customer.tolist()\n",
    "    \n",
    "#     def step(self,action,agent,state):\n",
    "# #         emb__1=self._get_emb_product(action)\n",
    "# #         emb__1=emb__1[action]\n",
    "#         #cr_,next_state=self.r_model(np.array([self._get_emb_product(action)]))\n",
    "#         done=False\n",
    "#         next_state_int=agent.get_action_r(self._get_emb_product(action))\n",
    "        \n",
    "#         if self._get_pr_from_index(next_state_int) in ('','[UNK]'):\n",
    "#             done=True\n",
    "#         next_state=self._get_pr_from_index(next_state_int)\n",
    "#         customer_interests,recommendation=self._get_cluster_from_cust_id(next_state,state)\n",
    "#         if recommendation[0] in customer_interests:\n",
    "#             reward=2\n",
    "#         reward=-1\n",
    "#         return next_state,reward,done\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c55a64",
   "metadata": {
    "id": "00c55a64"
   },
   "outputs": [],
   "source": [
    "class recommendation_Env:\n",
    "    \n",
    "    def __init__(self,data_path,text_vectorizer,emb_model,recursive_model):\n",
    "        #emb_model is product embeds model\n",
    "        # text vecorizer is products text_vectorizer\n",
    "        # emb_model is model for product embedding model\n",
    "        self.dataset=pd.read_csv(data_path,names=['index','pID','image','ratings','reviewtext','time','cust_id','cust_name','style','summary','unixtime','verified','vote'],low_memory=False)\n",
    "        self.t=text_vectorizer\n",
    "        self.vocab=self.t.get_vocabulary()\n",
    "        self.pr_model=emb_model\n",
    "        self.gcwd=self._get_cluster_with_data()\n",
    "        self.r_model=recursive_model\n",
    "    \n",
    "    def _get_products(self,cust_id:str):\n",
    "        return self.dataset[self.dataset.cust_id==cust_id]['pID'].values\n",
    "    \n",
    "    def _get_cluster_with_data(self):\n",
    "        self.kmeans = MiniBatchKMeans(n_clusters=5,random_state=42,batch_size=1024,max_iter=100)\n",
    "        self.kmeans.fit(self.pr_model(np.array(self.vocab).reshape(-1,1)).numpy())\n",
    "        return self.kmeans\n",
    "    \n",
    "    def _get_pr_from_index(self,index):\n",
    "        return self.vocab[index]\n",
    "    \n",
    "    def reset(self):\n",
    "        return '[UNK]'\n",
    "    \n",
    "    def _get_cluster_index(self,product_embedding):\n",
    "        #self.cluster=self._embeds_with_data()\n",
    "        \n",
    "        return self.gcwd.predict(product_embedding)\n",
    "    \n",
    "    def _get_emb_product(self,pr_id):\n",
    "        return self.pr_model(np.array([[self._get_pr_from_index(pr_id)]]))\n",
    "    \n",
    "    def _get_cluster_from_cust_id(self,index_for_recommended_product,state):\n",
    "        #self.embeds_from_cust_id=self.pr_model(self._get_products(cust_id)).numpy()\n",
    "        self.embeds_from_cust_id=self.pr_model(np.array([[state]])).numpy()\n",
    "        self.cluster_ids_for_customer=self._get_cluster_index(self.embeds_from_cust_id)\n",
    "        self.embeds_from_recommenation=self.pr_model(np.array([[index_for_recommended_product]])).numpy()\n",
    "        self.cluster_id_for_recomendation=self._get_cluster_index(self.embeds_from_recommenation)\n",
    "        return self.cluster_id_for_recomendation.tolist(),self.cluster_ids_for_customer.tolist()\n",
    "    \n",
    "    def step(self,action,agent,state):\n",
    "#         emb__1=self._get_emb_product(action)\n",
    "#         emb__1=emb__1[action]\n",
    "        #cr_,next_state=self.r_model(np.array([self._get_emb_product(action)]))\n",
    "        done=False\n",
    "        next_state_int=agent.get_action_r(self._get_emb_product(action))\n",
    "        \n",
    "        if self._get_pr_from_index(next_state_int) in ('','[UNK]'):\n",
    "            done=True\n",
    "        next_state=self._get_pr_from_index(next_state_int)\n",
    "        customer_interests,recommendation=self._get_cluster_from_cust_id(next_state,state)\n",
    "        if recommendation[0] in customer_interests:\n",
    "            reward=2\n",
    "        reward=-1\n",
    "        return next_state,reward,done\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629918fe",
   "metadata": {
    "id": "629918fe"
   },
   "outputs": [],
   "source": [
    "env=recommendation_Env('../data/AMAZON_FASHION.csv',product_embeds,model1,prod_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e9e2f",
   "metadata": {
    "id": "574e9e2f",
    "outputId": "b58d776a-1264-424f-de7d-02005035967b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('b00wxmir4e', -1, False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1245,agent,'[UNK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e80d4",
   "metadata": {
    "id": "b74e80d4",
    "outputId": "545b5fb2-fa6a-4c36-ae9d-ba544032954d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54677"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train(agent,env,2)\n",
    "agent.get_action_r(model1(np.array([['7106116521']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee9d14",
   "metadata": {
    "id": "b8ee9d14"
   },
   "outputs": [],
   "source": [
    "# train(agent,env,1,model1)\n",
    "import os\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fecdc",
   "metadata": {
    "id": "e32fecdc"
   },
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "log_dir='/logs/imdb-example/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "  for pid in Xtrain.pID.unique():\n",
    "    f.write(\"{}\\n\".format(pid))\n",
    "  # Fill in the rest of the labels with \"unknown\".\n",
    "  for unknown in range(1, 186191):\n",
    "    f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "# Save the weights we want to analyze as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, here\n",
    "# we will remove this value.\n",
    "weights = tf.Variable(model1.layers[2].get_weights()[0][1:])\n",
    "# Create a checkpoint from embedding, the filename and key are the\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config.\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694ce87",
   "metadata": {
    "id": "a694ce87",
    "outputId": "da80d70c-9a37-4456-8a81-d3f471d00dc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10288), started 0:09:01 ago. (Use '!kill 10288' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c96c632f74a2edd2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c96c632f74a2edd2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now run tensorboard against on log data we just saved.\n",
    "%tensorboard --logdir /logs/imdb-example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d89589",
   "metadata": {
    "id": "36d89589",
    "outputId": "4c3235e3-e875-4092-9d18-23366dd05cf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[-0.01369799]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 186191), dtype=float32, numpy=\n",
       " array([[[-0.00016137,  0.00032786, -0.00015888, ..., -0.00122273,\n",
       "           0.00126742,  0.00157114]]], dtype=float32)>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c_model(np.array([['']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d24491",
   "metadata": {
    "id": "99d24491"
   },
   "source": [
    "# its called embedding projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd82a4",
   "metadata": {
    "id": "82fd82a4",
    "outputId": "3bc924e5-8f27-421a-ff2e-f91a944b7c52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 128), dtype=float32, numpy=\n",
       "array([[[-4.7601487e-02, -3.5045672e-02, -2.0473052e-02,  7.7812187e-03,\n",
       "          3.5366405e-02, -2.8126348e-02,  4.2544808e-02,  4.2236004e-02,\n",
       "         -4.6327915e-02,  3.6636833e-02, -2.3304462e-02, -1.7544292e-02,\n",
       "         -4.2753387e-02,  1.3804268e-02,  2.8625820e-02, -1.5286207e-03,\n",
       "         -4.9141932e-02,  4.3871943e-02,  1.8376481e-02, -3.7240554e-02,\n",
       "          2.2750173e-02,  8.7446086e-03,  4.9775355e-03,  1.1903822e-02,\n",
       "         -4.1992329e-02,  3.4304857e-03, -9.2884786e-03,  1.9025330e-02,\n",
       "          3.3402573e-02, -1.8713724e-02, -4.6140529e-02, -2.1862149e-02,\n",
       "          3.5735536e-02, -1.5022110e-02, -3.9058030e-02, -4.7266509e-02,\n",
       "         -3.7030578e-02,  1.9349862e-02,  4.4185985e-02, -1.2529992e-02,\n",
       "          1.8964279e-02, -4.5682825e-02,  3.4722891e-02,  1.7310288e-02,\n",
       "          3.0591860e-03,  4.1655753e-02, -3.7192296e-02, -3.9230660e-04,\n",
       "         -4.3418493e-02, -1.1700392e-03, -4.5764830e-02,  2.5385011e-02,\n",
       "          4.8320521e-02,  4.3437369e-03,  6.1049312e-04,  4.0539827e-02,\n",
       "         -7.6560602e-03, -3.9890122e-02,  2.8168250e-02,  7.9519264e-03,\n",
       "          3.0223418e-02,  9.4360486e-03, -1.6072739e-02, -2.1735979e-02,\n",
       "          3.2960404e-02,  1.8093500e-02,  3.5759304e-02,  3.5659377e-02,\n",
       "         -1.4695443e-02,  1.4156584e-02, -2.1377945e-02,  4.9877279e-03,\n",
       "          4.2963624e-03,  4.6928491e-02,  1.9934867e-02,  4.3772426e-02,\n",
       "         -2.3591865e-02,  6.3984878e-03, -1.1252534e-02, -8.7427497e-03,\n",
       "         -3.6421012e-02, -3.1153847e-02,  1.9542549e-02, -2.6137793e-02,\n",
       "         -1.7158855e-02,  3.4532811e-02,  1.9761030e-02, -3.3350468e-02,\n",
       "          1.1407912e-02, -3.4191146e-02, -1.8829752e-02, -2.5777638e-02,\n",
       "          4.7560181e-02,  2.5328621e-03,  2.7625192e-02, -3.8209248e-02,\n",
       "          2.0793092e-02,  9.4358549e-03,  4.8357237e-02,  3.9711595e-06,\n",
       "         -3.8808871e-02, -3.2260217e-02,  3.6080565e-02, -4.6927597e-02,\n",
       "          2.9550362e-02, -3.0220700e-02,  1.8129181e-02, -1.5514158e-02,\n",
       "          1.2670431e-02, -5.3659901e-03, -1.0097217e-02,  2.1065250e-03,\n",
       "          3.1583574e-02, -1.0767661e-02,  4.9826730e-02,  2.0132508e-02,\n",
       "          4.9019698e-02,  3.9009545e-02, -2.1532012e-02,  1.6950104e-02,\n",
       "         -7.6409578e-03,  3.2567430e-02, -1.2706768e-02, -4.9489286e-02,\n",
       "          4.1307483e-02,  2.9423241e-02, -4.2883754e-03,  2.0560417e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_emb_model(np.array([['A1D4G1SNUZWQOT']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56430c05",
   "metadata": {
    "id": "56430c05",
    "outputId": "b7670980-3b2c-41bd-b416-fca9c6ce2749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 128), dtype=float32, numpy=\n",
       "array([[[-4.7601487e-02, -3.5045672e-02, -2.0473052e-02,  7.7812187e-03,\n",
       "          3.5366405e-02, -2.8126348e-02,  4.2544808e-02,  4.2236004e-02,\n",
       "         -4.6327915e-02,  3.6636833e-02, -2.3304462e-02, -1.7544292e-02,\n",
       "         -4.2753387e-02,  1.3804268e-02,  2.8625820e-02, -1.5286207e-03,\n",
       "         -4.9141932e-02,  4.3871943e-02,  1.8376481e-02, -3.7240554e-02,\n",
       "          2.2750173e-02,  8.7446086e-03,  4.9775355e-03,  1.1903822e-02,\n",
       "         -4.1992329e-02,  3.4304857e-03, -9.2884786e-03,  1.9025330e-02,\n",
       "          3.3402573e-02, -1.8713724e-02, -4.6140529e-02, -2.1862149e-02,\n",
       "          3.5735536e-02, -1.5022110e-02, -3.9058030e-02, -4.7266509e-02,\n",
       "         -3.7030578e-02,  1.9349862e-02,  4.4185985e-02, -1.2529992e-02,\n",
       "          1.8964279e-02, -4.5682825e-02,  3.4722891e-02,  1.7310288e-02,\n",
       "          3.0591860e-03,  4.1655753e-02, -3.7192296e-02, -3.9230660e-04,\n",
       "         -4.3418493e-02, -1.1700392e-03, -4.5764830e-02,  2.5385011e-02,\n",
       "          4.8320521e-02,  4.3437369e-03,  6.1049312e-04,  4.0539827e-02,\n",
       "         -7.6560602e-03, -3.9890122e-02,  2.8168250e-02,  7.9519264e-03,\n",
       "          3.0223418e-02,  9.4360486e-03, -1.6072739e-02, -2.1735979e-02,\n",
       "          3.2960404e-02,  1.8093500e-02,  3.5759304e-02,  3.5659377e-02,\n",
       "         -1.4695443e-02,  1.4156584e-02, -2.1377945e-02,  4.9877279e-03,\n",
       "          4.2963624e-03,  4.6928491e-02,  1.9934867e-02,  4.3772426e-02,\n",
       "         -2.3591865e-02,  6.3984878e-03, -1.1252534e-02, -8.7427497e-03,\n",
       "         -3.6421012e-02, -3.1153847e-02,  1.9542549e-02, -2.6137793e-02,\n",
       "         -1.7158855e-02,  3.4532811e-02,  1.9761030e-02, -3.3350468e-02,\n",
       "          1.1407912e-02, -3.4191146e-02, -1.8829752e-02, -2.5777638e-02,\n",
       "          4.7560181e-02,  2.5328621e-03,  2.7625192e-02, -3.8209248e-02,\n",
       "          2.0793092e-02,  9.4358549e-03,  4.8357237e-02,  3.9711595e-06,\n",
       "         -3.8808871e-02, -3.2260217e-02,  3.6080565e-02, -4.6927597e-02,\n",
       "          2.9550362e-02, -3.0220700e-02,  1.8129181e-02, -1.5514158e-02,\n",
       "          1.2670431e-02, -5.3659901e-03, -1.0097217e-02,  2.1065250e-03,\n",
       "          3.1583574e-02, -1.0767661e-02,  4.9826730e-02,  2.0132508e-02,\n",
       "          4.9019698e-02,  3.9009545e-02, -2.1532012e-02,  1.6950104e-02,\n",
       "         -7.6409578e-03,  3.2567430e-02, -1.2706768e-02, -4.9489286e-02,\n",
       "          4.1307483e-02,  2.9423241e-02, -4.2883754e-03,  2.0560417e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_emb_model(np.array([['A1D4G1SNUZWQOT']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35830d35",
   "metadata": {
    "id": "35830d35",
    "outputId": "2f3133d2-9a04-4d98-e36f-be040acd6f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[ 1.44032538e-02, -9.95387882e-02,  1.10612884e-02,\n",
       "         6.79661054e-03, -4.09440510e-02,  1.00643009e-01,\n",
       "        -1.96929991e-01, -3.08258086e-02,  3.37495469e-02,\n",
       "         2.14395046e-01,  8.11212361e-02,  4.69950475e-02,\n",
       "         2.28751451e-02, -2.81317890e-01, -1.18026860e-01,\n",
       "         1.51767880e-01, -3.65776196e-02,  2.22208768e-01,\n",
       "        -1.79001927e-01,  2.21132115e-01, -3.43354233e-02,\n",
       "        -7.58359879e-02,  8.15490484e-02, -2.65507072e-01,\n",
       "         8.10119137e-03, -1.77682005e-02,  9.54252258e-02,\n",
       "         8.51073191e-02, -2.06482112e-01,  8.72338414e-02,\n",
       "        -7.30938688e-02, -6.39760122e-02, -3.77323568e-01,\n",
       "         2.23182198e-02,  1.82245344e-01,  1.60314262e-01,\n",
       "        -3.36519064e-04, -2.05601931e-01,  1.85173184e-01,\n",
       "         1.34607881e-01, -5.43930903e-02,  6.04644455e-02,\n",
       "        -1.22840092e-01, -1.36357658e-02,  8.30601081e-02,\n",
       "        -1.54992715e-01, -1.03358604e-01, -8.81951228e-02,\n",
       "         1.68164447e-01, -1.89419493e-01,  1.02194779e-01,\n",
       "         1.65574029e-01,  3.90152410e-02,  7.91970044e-02,\n",
       "        -3.70503850e-02, -2.47278623e-02, -1.66196078e-02,\n",
       "        -1.31663650e-01,  2.95246169e-02, -1.47248775e-01,\n",
       "         7.72042722e-02, -1.49385408e-01, -1.83658659e-01,\n",
       "         2.28139162e-02,  2.10610777e-01,  7.46823326e-02,\n",
       "        -1.75207660e-01, -3.67743894e-02, -8.97192881e-02,\n",
       "        -5.51517643e-02, -6.78795353e-02, -3.51440832e-02,\n",
       "        -2.06257790e-01, -1.18607685e-01, -2.04361722e-01,\n",
       "        -3.96365710e-02,  2.11812049e-01,  2.07021341e-01,\n",
       "         8.51934999e-02, -1.08360583e-02,  8.46199617e-02,\n",
       "        -1.51869714e-01, -2.25236818e-01,  4.97977175e-02,\n",
       "        -1.73650041e-01, -2.97171444e-01,  3.33966017e-02,\n",
       "         1.74935818e-01,  8.04184750e-02,  1.45577326e-01,\n",
       "         2.99077719e-01, -9.17322859e-02,  1.71482608e-01,\n",
       "         1.21520236e-01,  2.47881606e-01,  1.04114316e-01,\n",
       "         6.42897487e-02,  7.30224177e-02,  1.93533227e-02,\n",
       "         1.73461899e-01, -1.25323534e-01, -4.89237234e-02,\n",
       "        -2.07048114e-02, -1.16258703e-01, -1.07622892e-01,\n",
       "        -4.10103463e-02,  1.23191066e-01, -1.02450453e-01,\n",
       "         3.37931901e-01, -5.21648936e-02, -1.25524439e-02,\n",
       "         1.24204181e-01, -6.78254068e-02,  1.94303557e-01,\n",
       "         5.96136600e-02,  1.78048655e-01, -1.81353718e-01,\n",
       "        -1.98687371e-02,  3.88140994e-04, -2.92851359e-01,\n",
       "        -1.50636107e-01, -9.57799032e-02,  8.88771340e-02,\n",
       "         7.36445934e-02,  1.26990020e-01, -1.02120169e-01,\n",
       "        -6.70978427e-02, -1.55738771e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(np.array([['7106116521']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9dddc",
   "metadata": {
    "id": "cbc9dddc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "99d24491"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2ce4e4610c0d989f68c8c665e56990395bb23154fc310710d1421a0758429e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
